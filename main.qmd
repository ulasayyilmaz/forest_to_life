---
title: "Deforestation-to-biodiversity"
author: "Ulas Ayyilmaz and Ishika"
format: pdf
execute:
  warning: false
  message: false
---

```{r}
#| echo: false
library(tidyverse)
library(ISLR)
library(tidymodels)
library(dplyr)
library("rgbif")
library(caret)
library(randomForest)
library(neuralnet)
library(readr)
```

```{r}
#change between 2000-2020 #https://www.globalforestwatch.org/dashboards/global/?category=forest-change&location=WyJnbG9iYWwiXQ%3D%3D&scrollTo=net-change
forest_data <- read_csv("net_tree_change.csv")
head(forest_data)

```

```{r}
top_5_loss <- forest_data |>
  arrange(desc(as.numeric(loss))) |>
  slice_head(n = 20)
top_5_gain <- forest_data |>
  arrange(desc(as.numeric(gain))) |>
  slice_head(n = 20)

top_5_net_desc <- forest_data |>
  arrange(desc(as.numeric(net))) |>
  slice_head(n = 20)

top_5_net_asc <- forest_data |>
  arrange(as.numeric(net)) |>
  slice_head(n = 20)

top_5_net_desc # poland, ukraine, uruguay, ireland, bangladesh
top_5_net_asc#tanzania, Mozambique, indonesia, DCcongo, paraguay
```
species of interest (check exist for each country)

Most net negative:
paraguay -
cod- 

most positive
ury
ukr
pol
ssd
bgd

All columns of a RGBIF EOD dataset
#"gbifID", "datasetKey", "occurrenceID", "kingdom", "phylum", "class", "order", "family", #"genus", "species", "infraspecificEpithet", "taxonRank", "scientificName", #"verbatimScientificName", "verbatimScientificNameAuthorship", "countryCode", "locality", #"stateProvince", "occurrenceStatus", "individualCount", "publishingOrgKey", #"decimalLatitude", "decimalLongitude", "coordinateUncertaintyInMeters", #"coordinatePrecision", "elevation", "elevationAccuracy", "depth", "depthAccuracy", #"eventDate", "day", "month", "year", "taxonKey", "speciesKey", "basisOfRecord", #"institutionCode", "collectionCode", "catalogNumber", "recordNumber", "identifiedBy", #"dateIdentified", "license", "rightsHolder", "recordedBy", "typeStatus", #"establishmentMeans", "lastInterpreted", "mediaType", "issue")


Ok, brainstorm time. Deforestation means removel of forests over time due to mostly due to human interference. Deforestation affects many things that contribute to human's well-being indirectly in a negative way. A direct effect is observed on the biodiversity - specifically birds who roam freely in forests. Other 


```{r}
# Parameters
countries <- c("RUS", "BRA", "CAN", "USA", "CHN", "IDN", "IND", "URY", "BLR", "UKR")  # Target countries
years <- 2000:2020  # Year range
bird_data<-name_suggest(q = "Aves", rank = "class", curlopts = list(timeout = 60))
bird_taxon_key <- bird_data$data$key
eod_dataset_key <- "4fa7b334-ce0d-4e88-aaae-2e0c138d049e"  # EOD datasetKey
bird_taxon_key
```

```{r}
# Define the target countries and years
countries <- c("URY","BLR","UKR","POL","SSD")  # Target countries
years <- c(2000, 2010, 2020)  # Year range
eod_dataset_key <- "4fa7b334-ce0d-4e88-aaae-2e0c138d049e"  # EOD datasetKey
species <- c("Coraciiformes","Strigiformes","Galliformes","Ciconiiformes")
```



```{r}
# Load necessary library
library(dplyr)  # For data manipulation

# Initialize an empty dataframe to store the combined data
combined_data <- data.frame()

# List of country names (folders inside the "data" directory)
countries <- c("poland", "ukraine", "uruguay", "ireland", "bangladesh",
               "tanzania", "Mozambique", "indonesia", "DCongo", "paraguay")

# Loop through each country's folder and combine all CSV files
for (country in countries) {
  # Path to the country's folder
  country_path <- file.path("data", country)
  
  # Get the list of CSV files in the country's folder
  csv_files <- list.files(country_path, pattern = "\\.csv$", full.names = TRUE)
  
  # Read each CSV file and add its content to the combined dataframe
  for (csv_file in csv_files) {
   tryCatch({
      # Read the CSV file (use read_delim for robustness)
      data <- read_delim(csv_file, delim = NULL, show_col_types = FALSE)
      
      # Add a column to identify the country
      data$country <- country
      
      # Append the data to the combined dataframe
      combined_data <- bind_rows(combined_data, data)
    }, error = function(e) {
      cat("Error reading file:", csv_file, "\n")
    })
  }
}

# Save the combined dataframe as a CSV file in the main directory
write.csv(combined_data, "all_bird_orders_data.csv", row.names = FALSE)

cat("Combined CSV file created as 'all_bird_orders_data.csv' in the main directory.\n")

```




```{r}
bird_orders <- read.csv(all_bird_orders_data.csv)
bird_orders
```

```{r}
#Step 2: Combine Forest and Bird Data
# Example forest data structure
forest_data <- data.frame(
  iso = c("RUS", "BRA", "CAN", "USA", "CHN"),
  loss = c(100, 200, 50, 150, 70),
  gain = c(300, 100, 400, 250, 500),
  net = c(200, -100, 350, 100, 430),
  change = c(10, -15, 20, 5, 18),
  gfw_area__ha = c(800000, 700000, 600000, 900000, 1000000)
)

# Merge bird and forest data
combined_data <- merge(bird_observation_counts, forest_data, by.x = "country", by.y = "iso", all.x = TRUE)

# Add dependent variable (change in bird observation)
combined_data <- combined_data %>%
  group_by(species) %>%
  mutate(observation_change = c(NA, diff(observation_count))) %>%
  ungroup()

# Drop rows with NA in key columns
model_data <- na.omit(combined_data)
```

```{r}
#Step 3: Train and Test Machine Learning Models
# Split data into training and testing sets
set.seed(42)
train_index <- createDataPartition(model_data$observation_change, p = 0.8, list = FALSE)
train_data <- model_data[train_index, ]
test_data <- model_data[-train_index, ]

# Prepare data for models
train_x <- train_data %>% select(-observation_change)
train_y <- train_data$observation_change
test_x <- test_data %>% select(-observation_change)
test_y <- test_data$observation_change

# K-Nearest Neighbors (KNN)
knn_tune <- train(
  x = train_x, y = train_y,
  method = "knn",
  tuneGrid = expand.grid(k = seq(1, 20, by = 2)),
  trControl = trainControl(method = "cv", number = 5)
)
best_knn <- knn_tune$bestTune$k

# Support Vector Machines (SVM)
svm_tune <- train(
  x = train_x, y = train_y,
  method = "svmRadial",
  tuneGrid = expand.grid(sigma = seq(0.01, 0.1, by = 0.01), C = seq(0.1, 1, by = 0.1)),
  trControl = trainControl(method = "cv", number = 5)
)

# Random Forest
rf_tune <- train(
  x = train_x, y = train_y,
  method = "rf",
  tuneGrid = expand.grid(mtry = seq(2, ncol(train_x), by = 1)),
  trControl = trainControl(method = "cv", number = 5),
  ntree = 500
)

# Neural Networks
nn_tune <- train(
  x = train_x, y = train_y,
  method = "nnet",
  tuneGrid = expand.grid(size = seq(1, 10, by = 1), decay = seq(0.01, 0.1, by = 0.01)),
  trControl = trainControl(method = "cv", number = 5),
  trace = FALSE
)

# Evaluate and compare models
results <- resamples(list(KNN = knn_tune, SVM = svm_tune, RF = rf_tune, NN = nn_tune))
summary(results)
```

```{r}
#Step 4: Identify Species with Highest Correlation
## Calculate correlations for each species
species_correlation <- model_data %>%
  group_by(species) %>%
  summarise(correlation = cor(observation_change, change, use = "complete.obs"), .groups = "drop")

# Identify top correlated species
top_species <- species_correlation %>%
  arrange(desc(abs(correlation))) %>%
  head(10)
top_species
```

