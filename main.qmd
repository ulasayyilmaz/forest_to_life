---
title: "Deforestation-to-biodiversity"
author: "Ulas Ayyilmaz and Ishika"
format: pdf
execute:
  warning: false
  message: false
---

```{r}
#| echo: false
library(tidyverse)
library(ISLR)
library(tidymodels)
library(dplyr)
library("rgbif")
library(caret)
library(randomForest)
library(neuralnet)
library(readr)
```

```{r}
#change between 2000-2020 #https://www.globalforestwatch.org/dashboards/global/?category=forest-change&location=WyJnbG9iYWwiXQ%3D%3D&scrollTo=net-change
forest_data <- read_csv("net_tree_change.csv")
head(forest_data)

```

```{r}
top_5_loss <- forest_data |>
  arrange(desc(as.numeric(loss))) |>
  slice_head(n = 20)
top_5_gain <- forest_data |>
  arrange(desc(as.numeric(gain))) |>
  slice_head(n = 20)

top_5_net_desc <- forest_data |>
  arrange(desc(as.numeric(net))) |>
  slice_head(n = 20)

top_5_net_asc <- forest_data |>
  arrange(as.numeric(net)) |>
  slice_head(n = 20)

top_5_net_desc # poland, ukraine, uruguay, ireland, bangladesh
top_5_net_asc#tanzania, Mozambique, indonesia, DCcongo, paraguay
```
order of interest (check exist for each country)

Most net negative:
PRY, COD, MOZ, IDN, TZA

most positive:
URY, UKR, POL,IRL, BGD

All columns of a RGBIF EOD dataset
#"gbifID", "datasetKey", "occurrenceID", "kingdom", "phylum", "class", "order", "family", #"genus", "species", "infraspecificEpithet", "taxonRank", "scientificName", #"verbatimScientificName", "verbatimScientificNameAuthorship", "countryCode", "locality", #"stateProvince", "occurrenceStatus", "individualCount", "publishingOrgKey", #"decimalLatitude", "decimalLongitude", "coordinateUncertaintyInMeters", #"coordinatePrecision", "elevation", "elevationAccuracy", "depth", "depthAccuracy", #"eventDate", "day", "month", "year", "taxonKey", "speciesKey", "basisOfRecord", #"institutionCode", "collectionCode", "catalogNumber", "recordNumber", "identifiedBy", #"dateIdentified", "license", "rightsHolder", "recordedBy", "typeStatus", #"establishmentMeans", "lastInterpreted", "mediaType", "issue")


Ok, brainstorm time. Deforestation means removel of forests over time due to mostly due to human interference. Deforestation affects many things that contribute to human's well-being indirectly in a negative way. A direct effect is observed on the biodiversity - specifically birds who roam freely in forests. Other 


```{r}
# Parameters
countries <- c("RUS", "BRA", "CAN", "USA", "CHN", "IDN", "IND", "URY", "BLR", "UKR")  # Target countries
years <- 2000:2020  # Year range
bird_data<-name_suggest(q = "Aves", rank = "class", curlopts = list(timeout = 60))
bird_taxon_key <- bird_data$data$key
eod_dataset_key <- "4fa7b334-ce0d-4e88-aaae-2e0c138d049e"  # EOD datasetKey
bird_taxon_key
```

```{r}
# Define the target countries and years
countries <- c("URY","BLR","UKR","POL","SSD")  # Target countries
years <- c(2000, 2010, 2020)  # Year range
eod_dataset_key <- "4fa7b334-ce0d-4e88-aaae-2e0c138d049e"  # EOD datasetKey
order <- c("Coraciiformes","Strigiformes","Galliformes","Ciconiiformes")
```



```{r}
# Load necessary library
library(dplyr)  # For data manipulation

# Initialize an empty dataframe to store the combined data
combined_data <- data.frame()

# List of country names (folders inside the "data" directory)
countries <- c( "poland","ukraine", "uruguay", "ireland", "bangladesh",
               "tanzania", "mozambique", "indonesia", "dcongo", "paraguay")
countries
# Loop through each country's folder and combine all CSV files
for (country in countries) {
  
  # Path to the country's folder
  country_path <- file.path("data", country)

    # Get the list of CSV files in the country's folder
  csv_files <- list.files(country_path, pattern = "\\.csv$", full.names = TRUE)

    # Read each CSV file and add its content to the combined dataframe
  for (csv_file in csv_files) {
   tryCatch({
      # Read the CSV file (use read_delim for robustness)
      data <- read_delim(csv_file, delim = NULL, show_col_types = FALSE)
      
      # Add a column to identify the country
      data$country <- country
      
      # Append the data to the combined dataframe
      combined_data <- bind_rows(combined_data, data)
    }, error = function(e) {
      cat("Error reading file:", csv_file, "\n")
    })
  }
}

# Save the combined dataframe as a CSV file in the main directory
write.csv(combined_data, "all_bird_orders_data.csv", row.names = FALSE)

cat("Combined CSV file created as 'all_bird_orders_data.csv' in the main directory.\n")

```

```{r}
bird_orders <- read.csv("all_bird_orders_data.csv")
head(bird_orders)
#596024662,584212444
```
info: all belong to aves class
#important columns to keep:
order, family, genus, species, stateProvince, individualCount, decimalLatitude, elevation,decimalLongitude, day,month, year, country

```{r}
filtered_bird_orders <- bird_orders |> 
  select(order, family, genus, species, stateProvince, individualCount, decimalLatitude, elevation,decimalLongitude, day,month, year, country)
head(filtered_bird_orders)
```

```{r}
country_mapping <- data.frame(
  iso = c("POL", "UKR", "URY", "IRL", "BGD", "TZA", "MOZ", "IDN", "COD", "PRY"),
  country = c("poland", "ukraine", "uruguay", "ireland", "bangladesh",
              "tanzania", "mozambique", "indonesia", "dcongo", "paraguay")
)

filtered_bird_orders$country <- tolower(filtered_bird_orders$country)

filtered_forest_data <- forest_data %>%
  filter(iso %in% country_mapping$iso) %>%   # Keep only rows with matching ISO codes
  left_join(country_mapping, by = "iso")  

# Combine the datasets based on the "country" column
combined_data <- left_join(filtered_bird_orders, filtered_forest_data, by = "country")

# Output the combined dataset
write.csv(combined_data, "filtered_forest_data.csv")
```

```{r}
joined_data <- read.csv("filtered_forest_data.csv")
joined_data
```

```{r}
#get rid of NA's in joined data
joined_data1 <- joined_data |>
  filter(!is.na(individualCount))

country_density_map <- joined_data1 |> 
  group_by(country,order,year)

country_density_map

```

```{r}
library(dplyr)
library(sf)
library(tidyr)
library(rnaturalearth)
```

```{r}
# Load world map data (you can use rnaturalearth for this)
world_map <- rnaturalearth::ne_countries(scale = "medium", returnclass = "sf")

# Filter world map for selected countries
country_maps <- world_map |> filter(name_long %in% countries)

# Iterate through each bird order and create maps for each country and year
bird_orders <- unique(country_density_map$order)

# Create a list to store plots
plots <- list()

for (bird_order in bird_orders) {
  for (year in years) {
    for (country in countries) {
      # Filter data for the specific bird order, year, and country
      specific_data <- country_density_map |>
        filter(order == bird_order, year == year, country == country)
      
      # Join country map with bird observation data
      country_map <- country_maps |> filter(name_long == country)

      # Create the plot
      p <- ggplot() +
        geom_sf(data = country_map, fill = "grey90", color = "black") +
        geom_point(data = specific_data, 
                   aes(x = decimalLongitude, y = decimalLatitude, size = individualCount),
                   alpha = 0.7) +
        scale_size_continuous(name = "Count", range = c(1, 10)) +
        ggtitle(paste("Bird Order:", bird_order, "Year:", year, "Country:", country)) +
        theme_minimal()

      # Save the plot in the list
      plots[[paste(bird_order, year, country, sep = "_")]] <- p
    }
  }
}
# ggsave("bird_density_map.png", plots[[1]], width = 10, height = 7)
# Example: Display the first plot
print(plots[[111]])

```


```{r}
# Verify data for Poland across the years
poland_data <- joined_data |>
  filter(country == "poland", year %in% years, order %in% order)

# Print a summary of the data for Poland
summary(poland_data)

# Check distinct combinations of year and observation locations (latitude/longitude)
distinct_poland_data <- poland_data |>
  select(year, decimalLatitude, decimalLongitude, individualCount) |>
  distinct()

# Print the distinct combinations
print(distinct_poland_data)

# Check the total individualCount per year for Poland
counts_per_year <- poland_data |>
  group_by(year) |>
  summarise(total_count = sum(individualCount, na.rm = TRUE))

# Print total counts
print(counts_per_year)

```


```{r}
print(plots[[1]])
print(plots[[11]])
print(plots[[31]])
```




```{r}
# Aggregate bird count by order, country, and year
order_counts <- joined_data %>%
  group_by(order, country, year) %>%
  summarize(order_count = sum(individualCount, na.rm = TRUE), .groups = "drop")

order_counts
```


```{r}
# Merge aggregated counts back with deforestation data
model_data <- joined_data %>%
  select(country, year, iso, stable, loss, gain, disturb, net, change, gfw_area__ha) %>%
  distinct() %>%
  inner_join(order_counts, by = c("country", "year"))

head(model_data, 50)
```

```{r}
set.seed(123)  # For reproducibility
library(caret)

# Split the data into training and testing sets
split_index <- createDataPartition(model_data$order_count, p = 0.8, list = FALSE)
train_data <- model_data[split_index, ]
test_data <- model_data[-split_index, ]

```

```{r}
library(randomForest)
library(caret)

# Random forest model with tuning
rf_model <- train(
  order_count ~ stable + loss + gain + disturb + net + change + gfw_area__ha,
  data = train_data,
  method = "rf",
  trControl = trainControl(method = "oob", search = "grid"),
  tuneGrid = expand.grid(mtry = 2:6)  # Test different values of mtry
)

# Print results
print(rf_model)

# Visualize the trained random forest model
plot(rf_model)

```

```{r}
#calculate prediction accuracy for train and test data with the trained random forest

```


```{r}
library(e1071)

# SVM model with tuning
svm_model <- train(
  order_count ~ stable + loss + gain + disturb + net + change + gfw_area__ha,
  data = train_data,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 10),  # 10-fold cross-validation
  tuneGrid = expand.grid(sigma = seq(0.01, 0.1, length.out = 5), C = seq(0.1, 1, length.out = 5))
)

# Print results
print(svm_model)

# Visualize SVM model performance
plot(svm_model)

```

```{r}
#calculate prediction accuracy
```


```{r}
# KNN model with tuning
knn_model <- train(
  order_count ~ stable + loss + gain + disturb + net + change + gfw_area__ha,
  data = train_data,
  method = "knn",
  trControl = trainControl(method = "cv", number = 10),  # 10-fold cross-validation
  tuneGrid = expand.grid(k = seq(1, 15, by = 2))  # Test different values of k
)

# Print results
print(knn_model)

# Visualize the KNN model performance
plot(knn_model)

```

```{r}
# Make predictions
rf_preds <- predict(rf_model, test_data)
knn_preds <- predict(knn_model, test_data)
svm_preds <- predict(svm_model, test_data)

# Evaluate performance (example: RMSE)
rf_rmse <- RMSE(rf_preds, test_data$order_count)
knn_rmse <- RMSE(knn_preds, test_data$order_count)
svm_rmse <- RMSE(svm_preds, test_data$order_count)

cat("Random Forest RMSE:", rf_rmse, "\n")
cat("KNN RMSE:", knn_rmse, "\n")
cat("SVM RMSE:", svm_rmse, "\n")
```

```{r}
# Variable importance plot
varImpPlot(rf_model$finalModel)
```
```{r}
# Predict order_count using each model
rf_preds <- predict(rf_model, test_data)  # Random Forest predictions
knn_preds <- predict(knn_model, test_data)  # KNN predictions
svm_preds <- predict(svm_model, test_data)  # SVM predictions

# Load necessary library for evaluation metrics
library(Metrics)

# Define metrics
calc_metrics <- function(actual, predicted) {
  r_squared <- cor(actual, predicted)^2
  rmse_val <- rmse(actual, predicted)
  mae_val <- mae(actual, predicted)
  
  return(data.frame(
    R_Squared = r_squared,
    RMSE = rmse_val,
    MAE = mae_val
  ))
}

# Calculate metrics for each model
rf_metrics <- calc_metrics(test_data$order_count, rf_preds)
knn_metrics <- calc_metrics(test_data$order_count, knn_preds)
svm_metrics <- calc_metrics(test_data$order_count, svm_preds)

# Combine results for comparison
model_metrics <- rbind(
  cbind(Model = "Random Forest", rf_metrics),
  cbind(Model = "KNN", knn_metrics),
  cbind(Model = "SVM", svm_metrics)
)

print(model_metrics)


```
```{r}
# Combine actual and predicted data for visualization
test_results <- test_data %>%
  mutate(
    RF_Preds = rf_preds,
    KNN_Preds = knn_preds,
    SVM_Preds = svm_preds
  )

# Create scatter plots for each model
library(ggplot2)

ggplot(test_results, aes(x = order_count, y = RF_Preds)) +
  geom_point(color = "blue") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "Random Forest Predictions vs Actual",
    x = "Actual Order Count",
    y = "Predicted Order Count"
  ) +
  theme_minimal()

ggplot(test_results, aes(x = order_count, y = KNN_Preds)) +
  geom_point(color = "green") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "KNN Predictions vs Actual",
    x = "Actual Order Count",
    y = "Predicted Order Count"
  ) +
  theme_minimal()

ggplot(test_results, aes(x = order_count, y = SVM_Preds)) +
  geom_point(color = "purple") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "SVM Predictions vs Actual",
    x = "Actual Order Count",
    y = "Predicted Order Count"
  ) +
  theme_minimal()

```

